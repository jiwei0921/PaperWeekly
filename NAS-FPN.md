# NAS-FPN: Learning Scalable Feature Pyramid Architecture for Object Detection

Golnaz Ghaisi et al. Google Brain

## Abstract 摘要

Current state-of-the-art convolutional architectures for object detection are manually designed. Here we aim to learn a better architecture of feature pyramid network for object detection. We adopt Neural Architecture Search and discover a new feature pyramid architecture in a novel scalable search space covering all cross-scale connections. The discovered architecture, named NAS-FPN, consists of a combination of top-down and bottom-up connections to fuse features across scales. NAS-FPN, combined with various backbone models in the RetinaNet framework, achieves better accuracy and latency tradeoff compared to state-of-the-art object detection models. NAS-FPN improves mobile detection accuracy by 2 AP compared to state-of-the-art SSDLite with MobileNetV2 model in [32] and achieves 48.3 AP which surpasses Mask R-CNN [10] detection accuracy with less computation time.

目前最好的目标检测卷积架构是手工设计出来的。这里我们的目标是学习一种更好的特征金字塔网络架构进行目标检测。我们采用NAS，在一个覆盖了所有跨尺度连接的新型可缩放搜索空间中，发现了一种新的特征金字塔架构。发现的架构名为NAS-FPN，包含了自上而下和自下而上连接的结合，以融合不同尺度的特征。NAS-FPN与RetinaNet框架中各种不同的骨干网络相结合，与目前最好的目标检测模型相比，得到了更好的准确率/延迟折中。NAS-FPN与目前最好的使用MobileNetV2模型的SSDLite相比，改进了2% AP，达到了48.3% AP，超过了Mask R-CNN检测准确率，耗费的时间还更少。

## 1. Introduction 引言

Learning visual feature representations is a fundamental problem in computer vision. In the past few years, great progress has been made on designing the model architecture of deep convolutional networks (ConvNets) for image classification [12, 15, 35] and object detection [21, 22]. Unlike image classification which predicts class probability for an image, object detection has its own challenge to detect and localize multiple objects across a wide range of scales and locations. To address this issue, the pyramidal feature representations, which represent an image with multiscale feature layers, are commonly used by many modern object detectors [11, 23, 26].

学习视觉特征表示是计算机视觉中的一个基础问题。在过去的几年里，在设计图像分类和目标检测的深度卷积网络架构中取得了很大进展。图像分类预测的是图像的类别概率，与之不同的是，目标检测是要在很多尺度和位置上检测并定位多个目标。为解决这个问题，金字塔特征表示，即将图像表示为多尺度特征层，在很多现代目标检测器中得到了广泛使用。

Feature Pyramid Network (FPN) [22] is one of the representative model architectures to generate pyramidal feature representations for object detection. It adopts a backbone model, typically designed for image classification, and builds feature pyramid by sequentially combining two adjacent layers in feature hierarchy in backbone model with top-down and lateral connections. The high-level features, which are semantically strong but lower resolution, are upsampled and combined with higher resolution features to generate feature representations that are both high resolution and semantically strong. Although FPN is simple and effective, it may not be the optimal architecture design. Recently, PANet [25] shows adding an extra bottom-up pathway on FPN features improves feature representations for lower resolution features. Many recent works [7, 16, 17, 34, 38, 39, 40, 43, 41] propose various cross-scale connections or operations to combine features to generate pyramidal feature representations.

生成金字塔特征表示进行目标检测的模型中，FPN是最很有代表性的一种模型架构。其采用了一种骨干模型，一般是为图像分类设计的，通过使用自上而下和横向连接将特征层次中相邻层结合起来，构建起特征金字塔。高层次特征，语义性很强，但是分辨率很低，经过上采样与高分辨率特征相结合，生成的特征表示分辨率高的同时语义也强。虽然FPN简单有效，可能不是最优的架构设计。最近，PANet证明了，在FPN特征上增加一个额外的自下而上的通道，可以改进更低分辨率特征的特征表示。很多最近的工作也提出了各种不同的跨尺度连接或运算，以将特征集合并生成金字塔特征表示。

The challenge of designing feature pyramid architecture is in its huge design space. The number of possible connections to combine features from different scales grow exponentially with the number of layers. Recently, Neural Architecture Search algorithm [44] demonstrates promising results on efficiently discovering top-performing architectures for image classification in a huge search space. To achieve their results, Zoph et al. [45] propose a modularized architecture that can be repeated and stacked into a scalable architecture. Inspired by [45], we propose the search space of scalable architecture that generates pyramidal representations. The key contribution of our work is in designing the search space that covers all possible cross-scale connections to generate multiscale feature representations. During the search, we aims to discover an atomic architecture that has identical input and output feature levels and can be applied repeatedly. The modular search space makes searching pyramidal architectures manageable. Another benefit of modular pyramidal architecture is the ability for anytime object detection (or “early exit”). Although such early exit approach has been attempted [14], manually designing such architecture with this constraint in mind is quite difficult.

设计特征金字塔架构的挑战在于其巨型设计空间。不同尺度上的特征的结合，带来的可能连接数量，随着层数的增长以指数级增长。最近，NAS算法[44]证明了在巨型搜索空间中搜索得到最好性能的图像分类架构是很有希望的。Zoph等[45]提出一种模块化的架构，可以重复堆叠成可扩展的架构，以得到其结果。受[45]启发，我们提出了可扩展架构的搜索空间，可以生成金字塔的表示。我们工作的关键贡献是，设计了搜索空间，覆盖了所有可能的跨尺度连接，以生成多尺度特征表示。在搜索过程中，我们的目标是找到一种原子架构，其输入特征水平和输出特征水平是相同的，并可以重复使用。模块化的搜索空间使得金字塔架构的搜索可控制。模块化金字塔架构的另一种好处是，可以进行任何时刻的目标检测（或早停）。虽然这种早停方法已经有所尝试[14]，手工设计这种约束的架构是很困难的。

The discovered architecture, named NAS-FPN, offers great flexibility in building object detection architecture. NAS-FPN works well with various backbone model, such as MobileNet [32], ResNet [12], and AmoebaNet [29]. It offers better tradeoff of speed and accuracy for both fast mobile model and accurate model. Combined with MobileNetV2 backbone in RetinaNet framework, it outperforms state-of-the-art mobile detection model of SSDLite with MobilenetV2 [32] by 2 AP given the same inference time. With strong AmoebaNet-D backbone model, NAS-FPN achieves 48.3 AP single model accuracy with single testing scale. The detection accuracy surpasses Mask R-CNN reported in [10] with even less inference time. A summary of our results is shown in Figure 1.

发现的架构称为NAS-FPN，在构建目标检测架构时非常灵活。NAS-FPN可以使用各种不同的骨干网络，如MobileNet，ResNet，AmoebaNet等。对于要求更快速的移动模型和要求更准确的模型，都有更好的速度/准确率折中。将MobileNetV2骨干的RetinaNet框架结合起来，超过了目前最好的移动检测模型MobileNetV2-SSDLite 2% AP，推理时间相同。结合强大的AmoebaNet-D骨干模型，NAS-FPN在单测试尺度下取得了48.3 AP单模型准确率。检测准确率超过了Mask R-CNN[10]，推理时间还更短。我们的结果总结如表1所示。

## 2. Related Works 相关工作

### 2.1. Architecture for Pyramidal Representations 金字塔表示的架构

Feature pyramid representations are the basis of solutions for many computer vision applications required multiscale processing [1]. However, using Deep ConvNets to generate pyramidal representations by featurizing image pyramid imposes large computation burden. To address this issue, recent works on human pose estimation, image segmentation, and object detection [8, 11, 22, 28, 31] introduce cross-scale connections in ConvNets that connect internal feature layers in different scales. Such connections effectively enhance feature representations such that they are not only semantically strong but also contain high resolution information. Many works have studied how to improve mutliscale feature presentations. Liu et.al [25] propose an additional bottom-up pathway based on FPN [22]. Recently, Zhao et al. [42] extends the idea to build stronger feature pyramid representations by employing multiple U-shape modules after a backbone model. Kong et al. [16] first combine features at all scales and generate features at each scale by a global attention operation on the combined features. Despite it is an active research area, most architecture designs of cross-scale connections remain shallow compared to the backbone model. In addition to manually design the cross-scale connections, [5, 27] propose to learn the connections through gating mechanism for visual counting and dense label predictions.

特征金字塔表示是很多需要多尺度处理的计算机视觉应用的解决方法的基础。但是，通过图像金字塔，使用深度卷积网络以生成金字塔表示，会带来很大的计算量负担。为解决这个问题，人体姿态估计、图像分割和目标检测的最近工作，都在ConvNets中引入了跨尺度的连接，连接了不同尺度下的内部特征层。这样的连接有效的增强了特征表示，这样特征不仅语义上很强，同时还包含高分辨率信息。很多工作都研究了怎样改进多尺度特征表示。Liu等[25]提出了在FPN中添加一种额外的自下而上通道。最近，Zhao等[42]拓展了这个思想，通过在骨干模型后采用多个U形模块，构建更强的特征金字塔表示。Kong等[16]首先将不同尺度的特征结合在一起，然后通过在结合特征上的全局注意力运算，生成每个尺度上的特征。虽然这是一个活跃的研究领域，多数跨尺度连接的架构设计与骨干模型相比仍然很浅。除了手工设计跨尺度连接，[5,27]提出了通过门机制来学习连接，进行视觉计数和密集标签预测。

In our work, instead of manually designing architectures for pyramidal representations, we use a combination of scalable search space and Neural Architecture Search algorithm to overcome the large search space of pyramidal architectures. We constrain the search to find an architecture that can be applied repeatedly. The architecture can therefore be used for anytime object detection (or “early exit”). Such early exit idea is related to [3, 37], especially in image classification [14].

我们的工作中，我们没有手工设计金字塔表示的架构，而是使用可扩展搜索空间和NAS算法的结合，以克服金字塔架构的大型搜索空间。我们对搜索进行约束，找到的架构要可以重复使用。这种架构因此可以用于任意时刻的目标检测（或早停）。这种早停思想与[3,37]相关，尤其是图像分类中[14]。

### 2.2. Neural Architecture Search 神经架构搜索

Our work is closely related to the work on Neural Architecture Search [44, 2, 45, 29]. Most notably, Zoph et al. [45] use a reinforcement learning with a controller RNN to design a cell (or a layer) to obtain a network, called NASNet which achieves state-of-the-art accuracy on ImageNet. The efficiency of the search process is further improved by [24] to design a network called PNASNet, with similar accuracy to NASNet. Similarly, an evolution method [29] has also been used to design AmoebaNets that improve upon NASNet and PNASNet. Since reinforcement learning and evolution controllers perform similarly well, we only experiment with a Reinforcement Learning controller in this paper. Our method has two major differences compared to [44]: (1) the outputs of our method are multiscale features whereas output of [44] is single scale features for classification; (2) our method specifically searches cross-scale connections, while [44] only focuses on discovering connections within the same feature resolution. Beyond image classification, Neural Architecture Search has also been used to improve image segmentation networks [4]. To the best of our knowledge, our work is the first to report success of applying Neural Architecture Search for pyramidal architecture in object detection. For a broader overview of related methods for Neural Architecture Search, please see [6].

我们的工作与NAS的工作很接近。最著名的是，Zoph等[45]使用一个带有RNN控制器的强化学习来设计一个单元（或一层）来得到一个网络，称为NASNet，在ImageNet中得到了当时最好的结果。搜索过程的效率在[24]中得到改进，设计了一种称为PNASNet的网络，其准确率与NASNet类似。类似的，[29]使用了一种演化方法来设计AmobaNets，在NASNet和PNASNet之上得到了改进。由于强化学习和演化算法控制器的表现都很不错，我们在本文中只用强化学习控制器进行试验。我们的方法与[44]相比有两处主要不同：(1)我们方法的输出是多尺度特征，而[44]的输出是用于分类的单尺度特征；(2)我们的方法专门搜索跨尺度连接，而[44]只关注于发现相同特征分辨率层之间的连接。在图像分类之外，NAS还用于改进图像分割网络。据我们所知，我们的工作是第一个将NAS成功的用于目标检测中的金字塔架构的。NAS相关方法的更多综述见[6]。

## 3. Method 方法

Our method is based on the RetinaNet framework [23] because it is simple and efficient. The RetinaNet framework has two main components: a backbone network (often state-of-the-art image classification network) and a feature pyramid network (FPN). The goal of the proposed algorithm is to discover a better FPN architecture for RetinaNet. Figure 2 shows the RetinaNet architecture.

我们的方法是基于RetinaNet框架的，因为简单高效。RetinaNet框架有两个主要组件：骨干网络（通常是目前最好的图像分类网络）和FPN。提出算法的目标是为RetinaNet发现一个更好的FPN架构。图2所示的是RetinaNet架构。

Figure 2: RetinaNet with NAS-FPN. In our proposal, feature pyramid network is to be searched by a neural architecture search algorithm. The backbone model and the subnets for class and box predictions follow the original design in RetinaNet [23]. The architecture of FPN can be stacked N times for better accuracy.

To discover a better FPN, we make use of the Neural Architecture Search framework proposed by [44]. The Neural Architecture Search trains a controller to select best model architectures in a given search space using reinforcement learning. The controller uses the accuracy of a child model in the search space as the reward signal to update its parameters. Thus through trial and error the controller learns to generate better architectures over time. As it has been identified by previous works [36, 44, 45], the search space plays a crucial role in the success of architecture search.

为发现一个更好的FPN，我们使用[44]提出的NAS框架。NAS训练了一个控制器在一个给定的搜索空间中用强化学习来选择最好的模型架构。控制器使用搜索空间中的一个子模型的准确率作为奖励信号来更新其参数。所以，通过试错，在一定时间之后，控制器学习生成了更好的架构。之前的工作已经验证了，搜索空间在架构搜索中扮演了关键的角色。

In the next section, we design a search space for FPN to generate feature pyramid representations. For scalability of the FPN (i.e., so that an FPN architecture can be stacked repeatedly within RetinaNet), during the search, we also force the the FPN to repeat itself N times and then concatenated into a large architecture. We call our feature pyramid architecture NAS-FPN.

下一节中，我们为FPN设计了一个搜索空间，以生成特征金字塔表示。为了FPN的可扩展性（即，一个FPN架构可以在RetinaNet中重复堆叠），在搜索过程中，我们还迫使FPN重复N次，然后拼接成一个大型架构。我们称我们的特征金字塔架构为NAS-FPN。

### 3.1. Architecture Search Space

In our search space, a feature pyramid network consists a number of “merging cells” that combine a number of input layers into representations for RetinaNet. In the following, we will describe the inputs into the Feature Pyramid Network, and how each merging cell is constructed.

在我们的搜索空间中，一个特征金字塔网络包括几个合并的单元，将几个输入层结合到用于RetinaNet的表示中。下面，我们描述FPN的输入，以及每个合并的单元是怎样构建的。

**Feature Pyramid Network**. A feature pyramid network takes multiscale feature layers as inputs and generate output feature layers in the identical scales as shown in Figure 2. We follow the design by RetinaNet [23] which uses the last layer in each group of feature layers as the inputs to the first pyramid network. The output of the first pyramid network are the input to the next pyramid network. We use as inputs features in 5 scales {C3, C4, C5, C6, C7} with corresponding feature stride of {8, 16, 32, 64, 128} pixels. The C6 and C7 are created by simply applying stride 2 and stride 4 max pooling to C5. The input features are then passed to a pyramid network consisting of a series of merging cells (see below) that introduce cross-scale connections. The pyramid network then outputs augmented multiscale feature representations {P3, P4, P5, P6, P7}. Since both inputs and outputs of a pyramid network are feature layers in the identical scales, the architecture of the FPN can be stacked repeatedly for better accuracy. In Section 4, we show controlling the number of pyramid networks is one simple way to tradeoff detection speed and accuracy.

**特征金字塔网络**。一个特征金字塔网络以多尺度特征层作为输入，生成同样尺度的输出特征层，如图2所示。我们根据RetinaNet的设计，即使用每个特征层组中的最后一层，作为第一个金字塔网络的输入。第一个金字塔网络的输出，是下一个金字塔网络的输入。我们使用五个尺度作为输入特征，即{C3, C4, C5, C6, C7}，对应的特征步长为{8, 16, 32, 64, 128}像素。C6和C7，就是对C5进行简单的步长为2和4的最大池化。输入特征然后送入一个金字塔网络，包含了一系列合并的单元（见下），这些单元引入了跨尺度的连接。金字塔网络然后输出增强的多尺度特征表示{P3, P4, P5, P6, P7}。由于金字塔网络的输入和输出是同样尺度的特征层，所以FPN的架构可以重复堆叠，以得到更好的准确率。在第4部分中，我们证明了，控制金字塔网络的数量，是检测速度和准确率的一种简单折中方式。

**Merging cell**. An important observation in previous works in object detection is that it is necessary to “merge” features at different scales. The cross-scale connections allow model to combine high-level features with strong semantics and low-level features with high resolution.

**合并的单元**。从之前的目标检测工作可以得到一个重要的观察结果，即合并不同尺度的特征是很有必要的。跨尺度的连接使模型可以将强语义的高层次特征与高分辨率的低层次特征结合到一起。

We propose merging cell, which is a fundamental building block of a FPN, to merge any two input feature layers into a output feature layer. In our implementation, each merging cell takes two input feature layers (could be from different scales), applies processing operations and then combines them to produce one output feature layer of a desired scale. A FPN consists of N different merging cells, where N is given during search. In a merging cell, all feature layers have the same number of filters. The process of constructing a merging cell is shown in Figure 3.

我们提出了合并单元，这是FPN的基础模块，将任意两个输入特征层结合成输出特征层。在我们的实现中，每个合并单元以两个特征层作为输入（可能是不同尺度的），进行处理后，将其结合到一起，生成一个理想尺度下的输出特征层。一个FPN包含N个不同的合并单元，其中在搜过过程中N是给定的。在一个合并单元中，所有特征层都有相同数量的滤波器。构建一个合并单元的过程如图3所示。

Figure 3: Four prediction steps required in a merging cell. Note the output feature layer is pushed back into the stack of candidate feature layers and available for selection for the next merging cell.

The decisions of how to construct the merging cell are made by a controller RNN. The RNN controller selects any two candidate feature layers and a binary operation to combine them into a new feature layer, where all feature layers may have different resolution. Each merging cell has 4 prediction steps made by distinct softmax classifiers:

怎样构建合并单元，是由控制器RNN决定的。RNN控制器选择任意两个候选特征层，和一个二值操作，以将其综合进一个新的特征层，其中所有的特征层可能分辨率是不同的。每个合并单元有4个预测步骤，由不同的softmax分类器进行预测：

**Step 1**. Select a feature layer hi from candidates. 从候选中选择一个特征层hi；
**Step 2**. Select another feature layer hj from candidates without replacement.从候选中选择另一个特征层hj；
**Step 3**. Select the output feature resolution. 选择输出分辨率；
**Step 4**. Select a binary op to combine hi and hj selected in Step 1 and Step 2 and generate a feature layer with the resolution selected in Step 3. 选择一个二值运算将步骤1和步骤2中选择的hi和hj结合到一起，生成一个特征层，其分辨率是步骤3选择的。

In step 4, we design two binary operations, sum and global pooling, in our search space as shown in Figure 4. These two operations are chosen for their simplicity and efficiency. They do not add any extra trainable parameters. The sum operation is commonly used for combining features [22]. The design of global pooling operation is inspired by [20]. We follow Pyramid Attention Networks [20] except removing convolution layers in the original design. The input feature layers are adjusted to the output resolution by nearest neighbor upsampling or max pooling if needed before applying the binary operation. The merged feature layer is always followed by a ReLU, a 3x3 convolution, and a batch normalization layer.

在步骤4中，我们在搜索空间中设计了两种二值运算，求和和全局池化，如图4所示。选择这两种运算是因为其简洁性和高效性，这两种运算没有增加其他额外的可训练参数。Sum运算经常用于叠加特征。全局池化运算的设计是受[20]启发。我们按照金字塔注意力网络[20]的思想进行，除了去除了原始设计中的卷积层。输入特征层调整到输出分辨率的方法，是通过最近邻上采样，或最大池化，这些运算是在使用二值运算之前。合并的特征层后都加入ReLU，3×3卷积和BN层。

The input feature layers to a pyramid network form the initial list of input candidates of a merging cell. In Step 5, the newly-generated feature layer is appended to the list of existing input candidates and becomes a new candidate for the next merging cell. There can be multiple candidate features share the same resolution during architecture search. To reduce computation in discovered architecture, we avoid selecting stride 8 feature in Step 3 for intermediate merging cells. In the end, the last 5 merging cells are designed to outputs feature pyramid {P3, P4, P5, P6, P7}. The order of output feature levels is predicted by the controller. Each output feature layer is then generated by repeating the step 1, 2, 4 until the output feature pyramid is fully generated. Similar to [44], we take all feature layers that have not been connected to any of output layer and sum them to the output layer that has the corresponding resolution.

金字塔网络的输入特征层，形成了合并单元的初始输入候选列表。在步骤5中，新生成的特征层，加入到现有的输入候选列表中，成为下一个合并单元的新候选。在架构搜索的过程中，同样分辨率的特征可以有多个候选。为降低发现的架构的计算量，我们在步骤3中避免为中间的合并单元选择步长为8的特征。在最后，最后的5个合并单元，设计为输出的特征金字塔{P3, P4, P5, P6, P7}。输出特征层级的顺序由控制器预测。重复进行步骤1,2,4，生成每个输出特征层，直到输出特征金字塔完全生成。与[44]类似，我们将没有和任何输出层想连接的所有特征层放到一起，对其进行求和，形成对应分辨率的输出层。

### 3.2. Deeply supervised Anytime Object Detection

One advantage of scaling NAS-FPN with stacked pyramid networks is that the feature pyramid representations can be obtained at output of any given pyramid network. This property enables anytime detection which can generate detection results with early exit. Inspired by [19, 13], we can attach classifier and box regression heads after all intermediate pyramid networks and train it with deep supervision [19]. During inference, the model does not need to finish the forward pass for all pyramid networks. Instead, it can stop at the output of any pyramid network and generate detection results. This can be a desirable property when computation resource or latency is a concern and provides a solution that can dynamically decide how much computation resource to allocate for generating detections. In Appendix A, we show NAS-FPN can be used for anytime detection.

堆叠金字塔网络的可扩展NAS-FPN的一个优点是，特征金字塔表示可以从任意给定的金字塔网络的输出得到。这种性质可以实现任意时刻的目标检测，即可以在早停的情况下生成检测结果。由[19,13]启发，我们可以将分类头和框回归头接到所有中间金字塔网络后，并用深度监督来训练[19]。在推理过程中，模型不需要完成所有金字塔网络的前向过程，而是可以在任意金字塔网络处停止推理，生成检测结果。这在计算资源受限，或延迟是一个重要考虑因素时，是一种非常理想的性质；可以动态决定使用多少计算资源来生成检测结果。在附录A中，我们可以看到NAS-FPN可以用于任意时刻的检测。

## 4. Experiments 试验

In this section, we first describe our experiments of Neural Architecture Search to learn a RNN controller to discover the NAS-FPN architecture. Then we demonstrate the discovered NAS-FPN works well with different backbone models and image sizes. The capacity of NAS-FPN can be easily adjusted by changing the number of stacking layers and the feature dimension in pyramid network. We show how to build accurate and fast architectures in the experiments.

在本节中，我们首先描述了NAS的试验中，学习一个RNN控制器来发现NAS-FPN架构。然后我们证明了发现的NAS-FPN在不同的骨干模型和图像大小下都工作良好。NAS-FPN的容量可以很容易的调整，即通过调整堆叠层的数量，和调整金字塔网络中的特征维度。我们在试验中展示了如何构建准确快速的架构。

### 4.1. Implementation Details 实现细节

We use the open-source implementation of RetinaNet for experiments. The models are trained on TPUs with 64 images in a batch. During training, we apply multiscale training with a random scale between [0.8, 1.2] to the output image size. The batch normalization layers are applied after all convolution layers. We use α = 0.25 and γ = 1.5 for focal loss. We use a weight decay of 0.0001 and a momentum of 0.9. The model is trained using 50 epochs. The initial learning rate 0.08 is applied for first 30 epochs and decayed 0.1 at 30 and 40 epochs. For experiments with DropBlock [9], we use a longer training schedule of 150 epochs with first decay at 120 and the second decay at 140 epochs. The step-wise learning rate schedule was not stable for training our model with AmoebaNet backbone on image size of 1280x1280 and for this case we use cosine learning rate schedule. The model is trained on COCO train2017 and evaluated on COCO val2017 for most experiments. In Table 1, we report test-dev accuracy to compare with existing methods.

我们使用开源实现的RetinaNet进行试验。模型在TPU上进行训练，一个批次64幅图像。在训练过程中，我们使用多尺度训练，随机尺度范围为输出图像大小的[0.8,1.2]。所有卷积层后都有BN层。我们在focal loss中使用α = 0.25，γ = 1.5。我们使用的权重衰减为0.0001，动量为0.9。模型训练了50轮。初始学习速率为0.08，训练30轮，在第30轮和40轮时衰减0.1。在DropBlock[9]的试验中，我们使用了150轮的训练方案，第一次衰减在120轮，第二次衰减在140轮。分步的学习速率方案，在使用AmoebaNet骨干网络进行训练，在图像大小为1280×1280时，还不是很稳定，在这种情况下，我们使用cosine学习速率的方案。大部分试验中，模型的训练是在COCO train2017上，评估在COCO val2017上。在表1中，我们与现有的方法进行了比较，给出test-dev的准确率。

### 4.2. Architecture Search for NAS-FPN

**Proxy task**. To speed up the training of the RNN controller we need a proxy task [45] that has a short training time and also correlates with the real task. The proxy task can then be used during the search to identify a good FPN architecture. We find that we can simply shorten the training of target task and use it as the proxy task. We only train the proxy task for 10 epochs, instead of 50 epochs that we use to train RetinaNet to converge. To further speed up training proxy task, we use a small backbone architecture of ResNet-10 with input 512 × 512 image size. With these reductions, the training time is 1hr for a proxy task on TPUs. We repeat the pyramid networks 3 times in our proxy task. The initial learning rate 0.08 is applied for first 8 epochs and decayed by the factor of 0.1 at epoch 8. We reserve a randomly selected 7392 images from the COCO train2017 set as the validation set, which we use to obtain rewards.

**代理任务**。为加速RNN控制器的训练，我们需要一个代理任务[45]，其训练时间要短，与真实任务要非常相关。代理任务在搜索过程中可以用于识别一个好的FPN架构。我们发现，我们可以缩短目标任务的训练时间，将其用作代理任务。我们只将代理任务训练10轮，而我们将RetinaNet训练50轮以得到收敛结果。为进一步加速训练代理任务，我们使用一个小的骨干架构，即输入为512×512的ResNet-10网络。通过这些缩减，代理任务在TPUs上的训练时间只需要1小时。我们在代理任务中将金字塔网络重复3次。初始学习速率为0.08，用于前8轮数据的训练，在第8轮时衰减为0.1倍。我们从COCO train 2017中保留随机选择的7392幅图像，作为验证集，用于得到rewards。

**Controller**. Similar to [44] our controller is a recurrent neural network (RNN) and it is trained using the Proximal Policy Optimization (PPO) [33] algorithm. The controller samples child networks with different architectures. These architectures are trained on a proxy task using a pool of workers. The workqueue in our experiments consisted of 100 Tensor Processing Units (TPUs). The resulting detection accuracy in average precision (AP) on a held-out validation set is used as the reward to update the controller. Figure 5-Left shows the AP of the sampled architectures for different iterations of training. As it can be seen the controller generated better architectures over time. Figure 5-Right shows total number of sampled architectures and also the total number of unique architectures generated by the RNN controller. The number of unique architectures converged after about 8000 steps. We use the architecture with the highest AP from all sampled architectures during RL training in our experiments. This architecture is first sampled at 8000 step and sampled many times after that. Figure 6 shows the details of this architecture.

**控制器**。与[44]类似，我们的控制器是RNN网络，使用Proximal Policy Optimization (PPO)[33]算法进行训练。控制器使用不同的架构对子网络进行取样。这些架构是用workers pool在代理任务上训练得到的。我们试验中的工作队列包括100个TPUs。在保留的验证集上得到的检测准确率（以AP为单位），用作更新控制器的reward。图5左展示了不同训练迭代数下采样架构的总数量。可以看到，随着时间的增加，控制器生成了更好的架构。图5右给出了，RNN控制器生成的取样架构的总数量，和唯一架构的总数量。唯一架构的数量在大约8000步时收敛。我们在试验的RL训练过程中，使用所有采样架构中最高AP的架构。这个架构首先取样8000步，然后还要取样很多次。图6给出了架构的细节。

Figure 5: Left: Rewards over RL training. The reward is computed as the AP of sampled architectures on the proxy task. Right: The number of sampled unique architectures to the total number of sampled architectures. As controller converges, more identical architectures are sampled by the controller.

Figure 6: Architecture of the discovered 7-merging-cell pyramid network in NAS-FPN with 5 input layers (yellow) and 5 output feature layers (blue). GP and R-C-B are stands for Global Pooling and ReLU-Conv-BatchNorm, respectively.

**Discovered feature pyramid architectures**. What makes a good feature pyramid architecture? We hope to shed lights on this question by visualizing the discovered architectures. In Figure 7(b-f), we plot NAS-FPN architectures with progressively higher reward during RL training. We find the RNN controller can quickly pick up some important crossscale connections in the early learning stage. For example, it discovers the connection between high resolution input and output feature layers, which is critical to generate high resolution features for detecting small objects. As the controller converges, the controller discovers architectures that have both top-down and bottom-up connections which is different from vanilla FPN in Figure 7(a). We also find better feature reuse as the controller converges. Instead of randomly picking any two input layers from the candidate pool, the controller learns to build connections on newly-generated layers to reuse previously computed feature representations.

**发现的特征金字塔架构**。怎样才是一个好的特征金字塔架构呢？我们希望通过可视化发现的架构来阐明这个问题。在图7(b-f)中，我们将在RL训练过程中逐渐增加的reward对应的NAS-FPN架构画了出来。我们发现RNN控制器可以在训练早期就迅速的选出一些重要的跨尺度连接。比如，它发现了高分辨率输入和输出特征层之间的连接，这对于生成高分辨率特征检测小目标非常关键。随着控制器的收敛，控制器发现的架构同时包含了自上而下和自下而上的连接，这与图7(a)的传统FPN不太一样。我们还新生成了一些层，以重用之前计算出来的特征表示。

Figure 7: Architecture graph of NAS-FPN. Each dot represents a feature layer. Feature layers in the same row have identical resolution. The resolution decreases in the bottom-up direction. The arrows indicate the connections between internal layers. The graph is constructed such that an input layer is on the left side. The inputs to a pyramid network are marked with green circles and outputs are marked with red circles. (a) The baseline FPN architecture. (b-f) The 7-cell NAS-FPN architectures discovered by Neural Architecture Search over training of the RNN controller. The discovered architectures converged as the reward (AP) of the proxy task progressively improves. (f) The final NAS-FPN that we used in our experiments.

### 4.3. Scalable Feature Pyramid Architecture 可扩展的特征金字塔架构

In this section, we show how to control the model capacity by adjusting (1) backbone model, (2) the number of repeated pyramid networks, and (3) the number of dimension in pyramid network. We discuss how these adjustments tradeoff computational time and speed. We define a simple notation to indicate backbone model and NAS-FPN capacity. For example, R-50, 5 @ 256 indicate a model using ResNet-50 backbone model, 5 stacked NAS-FPN pyramid networks, and 256 feature dimension.

本节中，我们展示了怎样控制模型容量，即通过调整(1)骨干模型，(2)重复金字塔网络的数量，(3)金字塔网络的维数。我们讨论这些调整怎样在计算时间和速度之间折中。我们定义了一个简单的表示，指示骨干模型和NAS-FPN的容量。比如，R-50,5@256表示模型使用ResNet-50骨干模型，5个堆叠的NAS-FPN金字塔网络，256个特征维度。

**Stacking pyramid networks**. Our pyramid network has a nice property that it can be scaled into a larger architecture by stacking multiple repeated architectures. In Figure 8a, we show that stacking the vanilla FPN architecture does not always improve performance whereas stacking NAS-FPN improves accuracy significantly. This result highlights our search algorithm can find scalable architectures, which may be hard to design manually. Interestingly, although we only apply 3 pyramid networks for the proxy task during the architecture search phase, the performance still improves with up to 7 pyramid networks applied.

**堆叠金字塔网络**。我们的金字塔网络有一个很好的性质，即可以通过堆叠多个重复的架构，从而扩展为更大的架构。在图8a中，我们说明了，堆叠传统FPN架构不一定改进性能，而堆叠NAS-FPN则显著的改进了准确率。这个结果强调了我们的搜索算法可以找到可扩展的架构，这通过手工设计是非常难的。有趣的是，虽然在架构搜索过程中，我们对代理任务只应用了三个金字塔网络，但在实际任务中，堆叠了7个金字塔网络仍然可以改进性能。

**Adopting different backbone architectures**. One common way to tradeoff accuracy and speed for object detection architectures is altering the backbone architecture. Although the pyramid network in NAS-FPN was discovered by using a light-weight ResNet-10 backbone architecture, we show that it can be transferred well across different backbone architectures. Figure 8b shows the performance of NAS-FPN on top of different backbones, from a lighter weight architecture such as MobilenetV2 to a very high capacity architecture such as AmoebaNet-D [29]. When we apply NAS-FPN with MobilenetV2 on the image size of 640 × 640, we get 36.6 AP with 160B FLOPs. Using state-of-the-art image classification architecture of AmoebaNet-D [29] as the backbone increases the FLOPs to 390B but also adds about 5 AP. NAS-FPN with both light and heavy backbone architectures benefits from stacking more pyramid networks.

**采用不同的骨干架构**。目标检测架构中，准确率与速度折中的一种常见方法是改变骨干架构。虽然NAS-FPN中的金字塔网络是通过使用轻量的ResNet-10骨干架构搜索而来的，我们证明了，在不同的骨干架构之间可以迁移的很好。图8b给出了NAS-FPN在不同的骨干下的性能，从轻量的架构如MobileNetV2，到容量很大的架构，如AmoebaNet-D。若使用MobileNetV2的NAS-FPN，输入图像大小为640×480，则计算量为FLOPs，36.6 AP。使用目前最好的图像分类架构AmoebaNet-D作为骨干，则FLOPs增加至390B，但AP也增加了5个点。使用轻量和重量级骨干架构的NAS-FPN，都会从堆叠更多的金字塔网络中受益。

**Adjusting feature dimension of feature pyramid networks**. Another way to increase the capacity of a model is to increase the feature dimension of feature layers in NAS-FPN. Figure 8c shows results of 128, 256, and 384 feature dimension in NAS-FPN with a ResNet-50 backbone architecture. Not surprisingly, increasing the feature dimension improves detection performance but it may not be an efficient way to improve the performance. In Figure 8c, R-50 7 @ 256, with much less FLOPs, achieves similar AP compared to R-50 3 @ 384. Increasing feature dimension would require model regularization technique. In Section 4.4, we discuss using DropBlock [9] to regularize the model.

**调整特征金字塔网络的特征维度**。增加模型容量的另一种方法是，增加NAS-FPN中特征层的特征维度。图8c给出了，使用ResNet-50骨干网络的NAS-FPN，在128,256,384个特征维度时的结果。和预期的一样，增加特征维度可以改进检测性能，但改进性能的效率不是太高。在图8c中，R-50 7@256以少的FLOPs取得了与R-50 3@384类似的AP。增加特征维度需要模型正则化技术。在4.4节中，我们讨论使用DropBlock来正则化模型的技术。

Figure 8: The model capacity of NAS-FPN can be controlled with (a) stacking pyramid networks, (b) changing the backbone architecture, and (c) increasing feature dimension in pyramid networks. All models are trained/tested on the image size of 640x640. Number above the marker indicates number of pyramid networks in NAS-FPN. (a) Number of pyramid networks (b) Backbone architectures (c) Feature dimension

**Architectures for high detection accuracy**. With the scalable NAS-FPN architecture, we discuss how to build an accurate model while remaining efficient. In Figure 9a, we first show that NAS-FPN R-50 5 @256 model has comparable FLOPs to the R-101 FPN baseline but with 2.5 AP gain. This shows using NAS-FPN is more effective than replacing the backbone with a higher capacity model. Going for a higher accuracy model, one can use a heavier backbone model or higher feature dimensions. Figure 9a shows that NAS-FPN architectures are in the upper left part in the accuracy to inference time figure compared to existing methods. The NAS-FPN is as accurate as to the state-of-the-art Mask R-CNN model with less computation time.

**高检测准确率的架构**。由于NAS-FPN架构可扩展，我们讨论一下怎样在保持高效的同时构建一个准确的模型。在图9a中，我们首先说明了，NAS-FPN R-50 5@256模型与R-101 FPN基准的FLOPs类似，但AP提升了2.5。这说明了，使用NAS-FPN比替换更准确的骨干，更有效率。追求更高准确率的模型，可以使用更高容量的骨干模型，或更多的特征维度。图9a说明了，与现有的方法比较起来，NAS-FPN架构是在准确率-推理时间图的左上部分的。NAS-FPN与目前最好的Mask R-CNN模型是一样准确的，但计算时间更少。

**Architectures for fast inference**. Designing object detector with low latency and limited computation budget is an active research topic. Here, we introduce NAS-FPNLite for mobile object detection. The major difference of NAS-FPNLite and NAS-FPN is that we search a pyramid network that has outputs from P3 to P6. Also we follow SSDLite [32] and replace convolution with depth-wise separable convolution in NAS-FPN. We discover a 15-cell architecture which yields good performance and use it in our experiments. We combine NAS-FPNLite and MobileNetV2 [32] in RetinaNet framework. For a fair comparison, we create a FPNLite baseline, which follows the original FPN structure and replaces all convolution layers with depth-wise separable convolution. Following [36, 32], we train NAS-FPNLite and FPNLite using an open-source object detection API. In Figure 9b, we control the feature dimension of NAS-FPN to be 48 or 64 so that it has similar FLOPs and CPU runtime on Pixel 1 as baseline methods and show that NAS-FPNLite outperforms both SSDLite [32] and FPNLite.

**快速推理的架构**。设计低延迟和有限计算量的目标检测器，是一个活跃的研究课题。这里，我们提出目标检测的NAS-FPNLite架构。NAS-FPNLite与NAS-FPN的主要区别是，我们搜索的金字塔网络，其输出是从P3到P6的。同时，我们还根据SSDLite[32]的思想，将NAS-FPN中的卷积替换为分层可分离卷积。我们发现了一种15单元架构，可以得到很好的性能，在我们的试验中进行应用。我们将NAS-FPNLite和MobileNetV2在RetinaNet架构进行结合。为公平比较，我们创建了一个FPNLite基准模型，有原始FPN的结构，但将所有的卷积层替换成了分层可分离卷积。按照[36,32]的方法，我们使用开源目标检测API训练NAS-FPNLite和FPNLite。如图9b所示，我们将NAS-FPN的特征维度控制在48或64，这样与基准模型在Pixel 1手机上有类似的FLOPs和CPU运行时间，这也说明了，NAS-FPNLite比SSDLite和FPNLite都更优秀。

Figure 9: Detection accuracy to inference time (left), FLOPs (middle), and parameters (right). (a) We compare to other high accuracy models. The inference time of all models are computed on a machine with P100 GPU. The green curves highlights results for NAS-FPN with different backbone architectures. The number above the marker indicates the number of repeats of pyramid networks in NAS-FPN. The feature dimension of NAS-FPN/FPN and input image size are mentioned next to each data point. (b) We compare to other fast models. The input image size of all models is 320x320 and the inference times are computed on Pixel 1 CPU. Our model are trained with light-weight model of MobileNetV2.

### 4.4. Further Improvements with DropBlock 进一步的改进

Due to the increased number of new layers introduced in NAS-FPN architecture, a proper model regularization is needed to prevent overfitting. Following the technique in [9], we apply DropBlock with block size 3x3 after batch normalization layers in the the NAS-FPN layers. Figure 10 shows DropBlock improves the performance of NAS-FPN. Especially, it improves more for architecture that has more newly introduced filters. Note that by default we do not apply DropBlock in previous experiments for the fair comparison to existing works.

由于NAS-FPN架构中引入了很多新层，因此需要合适的模型正则化，来防止过拟合。根据[9]中的方法，我们在NAS-FPN层中的BN层后使用模块大小3×3的DropBlock。图10说明了，DropBlock改进了NAS-FPN的性能。尤其是，引入的滤波器更多的架构，改进的就越多。注意，在默认情况下，之前的试验中是没有使用DropBlock的，以与现有的工作进行公平比较。

Figure 10: Performance comparison of NAS-FPN with feature dimension of 256 or 384 when it is trained with and without DropBlock (DB). Models are trained with backbone of ResNet-50 on image size of 1024x1024. Adding DropBlock is more important when we increase feature dimension in pyramid networks.

## 5. Conclusion 结论

In this paper, we proposed to use Neural Architecture Search to further optimize the process of designing Feature Pyramid Networks for Object Detection. Our experiments on the COCO dataset showed that the discovered architecture, named NAS-FPN, is flexible and performant for building accurate detection model. On a wide range of accuracy and speed tradeoff, NAS-FPN produces significant improvements upon many backbone architectures.

本文中，我们提出使用NAS来进一步优化设计目标检测的FPN架构的过程。我们在COCO数据集上的试验表明，发现的架构可以灵活的构建性能很好的高准确率检测模型，称为NAS-FPN。在很广的准确率与速度的折中范围中，NAS-FPN在很多骨干架构下都得到了明显的改进。